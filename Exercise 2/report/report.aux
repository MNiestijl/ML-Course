\relax 
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Decision boundary of decision stump using data from two normal distributions with the identity as covariance matrix and mean $[0,0]^{T}, [0,2]^{T}$ respectively. In the left image, the original data was used whereas in the right image, the second feature was scaled by a factor $3$.\relax }}{2}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:scatter}{{1}{2}}
\newlabel{fig:scatter@cref}{{[figure][1][0]1}{2}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Decision boundary of decision stump using differently weighted data. The data is obtained as in \textbf  {c.}\relax }}{3}}
\newlabel{weights}{{2}{3}}
\newlabel{weights@cref}{{[figure][2][0]2}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Decision boundary after $N$ iterations. The training data is shown as a scatter plot and the yellow circles indicate the five objects with the highest weight at the last performed iteration. \relax }}{4}}
\newlabel{decision_boundary1}{{3}{4}}
\newlabel{decision_boundary1@cref}{{[figure][3][0]3}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Decision boundary after $N$ iterations. The training data is shown as a scatter plot and the yellow circles indicate the five objects with the highest weight at the last performed iteration.\relax }}{5}}
\newlabel{decision_boundary2}{{4}{5}}
\newlabel{decision_boundary2@cref}{{[figure][4][0]4}{5}}
